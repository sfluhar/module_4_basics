{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These packages allow us to turn web pages into objects, convert those objects into text, search the text, and save the results in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Craigslist works to prevent web scraping. If you go to the \"Garage & Moving Sales\" page the Phoenix Craigslist site, and enter keywords, you will get a list of results. But if you inspect the html code, you will not find any classes that contain the metadata about your search results. Instead, you have to individually open each result as its own page. Only then will the divs, sections, and classes become apparent. I used this manual method to obtain \"a list of URLs,\" per the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_urls = ['https://phoenix.craigslist.org/wvl/gms/d/glendale-estate-sale/7588379037.html',\n",
    "                'https://phoenix.craigslist.org/evl/gms/d/tempe-everything-in-my-1020-storage/7578328538.html',\n",
    "               'https://tucson.craigslist.org/gms/d/tucson-mini-estate-sale-starting-sunday/7588604990.html',\n",
    "               'https://tucson.craigslist.org/gms/d/tucson-moving-sales/7586073631.html',\n",
    "               'https://phoenix.craigslist.org/evl/gms/d/mesa-moving-feb-20-priced-to-sell/7582745739.html',\n",
    "               'https://phoenix.craigslist.org/nph/gms/d/scottsdale-estate-sale-final-days-of/7566676009.html',\n",
    "               'https://yuma.craigslist.org/gms/d/quartzsite-huge-rock-auction-feb-16th/7588705227.html']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section uses requests to retrieve the html code for each page, BeautifulSoup to parse the page and find specific elements, Python to test the strings returned to see if they contain keywords, and Pandas to load a DataFrame with the links and keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['link', 'keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in list_of_urls:\n",
    "    thispage = requests.get(link)\n",
    "    bs = BeautifulSoup(thispage.text,'html.parser')\n",
    "    match = bs.find(\"section\", {\"id\": \"postingbody\"})\n",
    "    if 'mattress' in match.text:\n",
    "        keyword = 'mattress'\n",
    "    elif 'cabinet' in match.text:\n",
    "        keyword = 'cabinet'\n",
    "    elif 'wrench' in match.text:\n",
    "        keyword = 'wrench'\n",
    "    sleep(15)\n",
    "    df_row = {'link': link, 'keyword': keyword}\n",
    "    df = df.append(df_row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section displays the contents of the DataFrame and saves it as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://phoenix.craigslist.org/wvl/gms/d/glend...</td>\n",
       "      <td>mattress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://phoenix.craigslist.org/evl/gms/d/tempe...</td>\n",
       "      <td>mattress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://tucson.craigslist.org/gms/d/tucson-min...</td>\n",
       "      <td>mattress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://tucson.craigslist.org/gms/d/tucson-mov...</td>\n",
       "      <td>mattress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://phoenix.craigslist.org/evl/gms/d/mesa-...</td>\n",
       "      <td>cabinet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://phoenix.craigslist.org/nph/gms/d/scott...</td>\n",
       "      <td>cabinet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://yuma.craigslist.org/gms/d/quartzsite-h...</td>\n",
       "      <td>cabinet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link   keyword\n",
       "0  https://phoenix.craigslist.org/wvl/gms/d/glend...  mattress\n",
       "1  https://phoenix.craigslist.org/evl/gms/d/tempe...  mattress\n",
       "2  https://tucson.craigslist.org/gms/d/tucson-min...  mattress\n",
       "3  https://tucson.craigslist.org/gms/d/tucson-mov...  mattress\n",
       "4  https://phoenix.craigslist.org/evl/gms/d/mesa-...   cabinet\n",
       "5  https://phoenix.craigslist.org/nph/gms/d/scott...   cabinet\n",
       "6  https://yuma.craigslist.org/gms/d/quartzsite-h...   cabinet"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('module_4_basics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
